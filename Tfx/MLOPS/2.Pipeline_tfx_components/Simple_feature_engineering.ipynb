{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Simple_feature_engineering.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPm7j7eAVhyPxO5ZP6GiwTH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YNMHhjEFJNSB"},"source":["For this introductory exercise, you will walk through the \"Hello World\" of using TensorFlow Transform to preprocess input data. As you've seen in class, the main steps are to:\n","\n","1. Collect raw data\n","2. Define metadata\n","3. Create a preprocessing function\n","4. Generate a constant graph with the required transformations\n","\n","Let's begin!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"USkr9ImMI0dx","executionInfo":{"status":"ok","timestamp":1632811807813,"user_tz":-600,"elapsed":145730,"user":{"displayName":"Data Guru","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14667720544529076765"}},"outputId":"baf440f6-2e52-490c-a5d9-fc11a2658f88"},"source":["!pip install tfx"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tfx\n","  Downloading tfx-1.2.0-py3-none-any.whl (2.4 MB)\n","\u001b[K     |████████████████████████████████| 2.4 MB 5.1 MB/s \n","\u001b[?25hCollecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2\n","  Downloading tensorflow-2.5.1-cp37-cp37m-manylinux2010_x86_64.whl (454.4 MB)\n","\u001b[K     |████████████████████████████████| 454.4 MB 8.9 kB/s \n","\u001b[?25hRequirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tfx) (1.3.9)\n","Collecting apache-beam[gcp]<3,>=2.31\n","  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 39.2 MB/s \n","\u001b[?25hCollecting google-cloud-bigquery<2.21,>=1.28.0\n","  Downloading google_cloud_bigquery-2.20.0-py2.py3-none-any.whl (189 kB)\n","\u001b[K     |████████████████████████████████| 189 kB 44.1 MB/s \n","\u001b[?25hCollecting google-cloud-aiplatform<0.8,>=0.5.0\n","  Downloading google_cloud_aiplatform-0.7.1-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 55.6 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client<2,>=1.8 in /usr/local/lib/python3.7/dist-packages (from tfx) (1.12.8)\n","Collecting tfx-bsl<1.3.0,>=1.2.0\n","  Downloading tfx_bsl-1.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (19.0 MB)\n","\u001b[K     |████████████████████████████████| 19.0 MB 22 kB/s \n","\u001b[?25hCollecting ml-pipelines-sdk==1.2.0\n","  Downloading ml_pipelines_sdk-1.2.0-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 48.4 MB/s \n","\u001b[?25hCollecting tensorflow-transform<1.3.0,>=1.2.0\n","  Downloading tensorflow_transform-1.2.0-py3-none-any.whl (406 kB)\n","\u001b[K     |████████████████████████████████| 406 kB 75.3 MB/s \n","\u001b[?25hCollecting ml-metadata<1.3.0,>=1.2.0\n","  Downloading ml_metadata-1.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 29.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub<0.13,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from tfx) (0.12.0)\n","Requirement already satisfied: jinja2<3,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from tfx) (2.11.3)\n","Requirement already satisfied: numpy<1.20,>=1.16 in /usr/local/lib/python3.7/dist-packages (from tfx) (1.19.5)\n","Requirement already satisfied: grpcio<2,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from tfx) (1.40.0)\n","Requirement already satisfied: pyyaml<6,>=3.12 in /usr/local/lib/python3.7/dist-packages (from tfx) (3.13)\n","Collecting kubernetes<13,>=10.0.1\n","  Downloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 60.8 MB/s \n","\u001b[?25hCollecting pyarrow<3,>=1\n","  Downloading pyarrow-2.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.7 MB)\n","\u001b[K     |████████████████████████████████| 17.7 MB 77 kB/s \n","\u001b[?25hCollecting attrs<21,>=19.3.0\n","  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.7/dist-packages (from tfx) (3.17.3)\n","Collecting tensorflow-model-analysis<0.34,>=0.33\n","  Downloading tensorflow_model_analysis-0.33.0-py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 74.5 MB/s \n","\u001b[?25hCollecting packaging<21,>=20\n","  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 5.9 MB/s \n","\u001b[?25hCollecting tensorflow-data-validation<1.3.0,>=1.2.0\n","  Downloading tensorflow_data_validation-1.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 67.8 MB/s \n","\u001b[?25hCollecting docker<5,>=4.1\n","  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 44.0 MB/s \n","\u001b[?25hCollecting google-apitools<1,>=0.5\n","  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n","\u001b[K     |████████████████████████████████| 135 kB 59.7 MB/s \n","\u001b[?25hCollecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15\n","  Downloading tensorflow_serving_api-2.6.0-py2.py3-none-any.whl (37 kB)\n","Collecting keras-tuner<1.0.2,>=1\n","  Downloading keras-tuner-1.0.1.tar.gz (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py<0.13,>=0.9 in /usr/local/lib/python3.7/dist-packages (from tfx) (0.12.0)\n","Requirement already satisfied: click<8,>=7 in /usr/local/lib/python3.7/dist-packages (from tfx) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py<0.13,>=0.9->tfx) (1.15.0)\n","Collecting avro-python3!=1.9.2,<1.10.0,>=1.8.1\n","  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 57.7 MB/s \n","\u001b[?25hCollecting orjson<4.0\n","  Downloading orjson-3.6.3-cp37-cp37m-manylinux_2_24_x86_64.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 50.1 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (2.8.2)\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (2018.9)\n","Collecting requests<3.0.0,>=2.24.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 804 kB/s \n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (1.7)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (1.3.0)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (3.12.0)\n","Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (4.1.3)\n","Collecting future<1.0.0,>=0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 56.3 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Collecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 55.6 MB/s \n","\u001b[?25hRequirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (0.17.4)\n","Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (3.7.4.3)\n","Collecting google-cloud-videointelligence<2,>=1.8.0\n","  Downloading google_cloud_videointelligence-1.16.1-py2.py3-none-any.whl (183 kB)\n","\u001b[K     |████████████████████████████████| 183 kB 58.4 MB/s \n","\u001b[?25hCollecting google-cloud-language<2,>=1.3.0\n","  Downloading google_cloud_language-1.3.0-py2.py3-none-any.whl (83 kB)\n","\u001b[K     |████████████████████████████████| 83 kB 2.0 MB/s \n","\u001b[?25hCollecting google-cloud-vision<2,>=0.38.0\n","  Downloading google_cloud_vision-1.0.0-py2.py3-none-any.whl (435 kB)\n","\u001b[K     |████████████████████████████████| 435 kB 58.7 MB/s \n","\u001b[?25hCollecting google-cloud-dlp<2,>=0.12.0\n","  Downloading google_cloud_dlp-1.0.0-py2.py3-none-any.whl (169 kB)\n","\u001b[K     |████████████████████████████████| 169 kB 42.8 MB/s \n","\u001b[?25hRequirement already satisfied: google-auth<2,>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (1.35.0)\n","Requirement already satisfied: google-cloud-core<2,>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (1.0.3)\n","Collecting google-cloud-spanner<2,>=1.13.0\n","  Downloading google_cloud_spanner-1.19.1-py2.py3-none-any.whl (255 kB)\n","\u001b[K     |████████████████████████████████| 255 kB 59.7 MB/s \n","\u001b[?25hCollecting grpcio-gcp<1,>=0.2.2\n","  Downloading grpcio_gcp-0.2.2-py2.py3-none-any.whl (9.4 kB)\n","Collecting google-cloud-pubsub<2,>=0.39.0\n","  Downloading google_cloud_pubsub-1.7.0-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 51.9 MB/s \n","\u001b[?25hCollecting google-cloud-bigtable<2,>=0.31.1\n","  Downloading google_cloud_bigtable-1.7.0-py2.py3-none-any.whl (267 kB)\n","\u001b[K     |████████████████████████████████| 267 kB 73.2 MB/s \n","\u001b[?25hCollecting google-apitools<1,>=0.5\n","  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n","\u001b[K     |████████████████████████████████| 173 kB 73.2 MB/s \n","\u001b[?25hCollecting google-cloud-recommendations-ai<=0.2.0,>=0.1.0\n","  Downloading google_cloud_recommendations_ai-0.2.0-py2.py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 69.9 MB/s \n","\u001b[?25hRequirement already satisfied: cachetools<5,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (4.2.2)\n","Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.31->tfx) (1.8.0)\n","Collecting websocket-client>=0.32.0\n","  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->tfx) (1.26.3)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->tfx) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->tfx) (0.0.4)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.8->tfx) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.8->tfx) (1.53.0)\n","Collecting fasteners>=0.14\n","  Downloading fasteners-0.16.3-py2.py3-none-any.whl (28 kB)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.31->tfx) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.18.0->apache-beam[gcp]<3,>=2.31->tfx) (4.7.2)\n","Collecting google-cloud-storage<2.0.0dev,>=1.26.0\n","  Downloading google_cloud_storage-1.42.2-py2.py3-none-any.whl (105 kB)\n","\u001b[K     |████████████████████████████████| 105 kB 73.9 MB/s \n","\u001b[?25hCollecting proto-plus>=1.10.1\n","  Downloading proto_plus-1.19.0-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n","\u001b[?25hCollecting google-cloud-core<2,>=0.28.1\n","  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n","Collecting google-cloud-bigquery<2.21,>=1.28.0\n","  Downloading google_cloud_bigquery-2.19.0-py2.py3-none-any.whl (188 kB)\n","\u001b[K     |████████████████████████████████| 188 kB 74.4 MB/s \n","\u001b[?25h  Downloading google_cloud_bigquery-2.18.0-py2.py3-none-any.whl (188 kB)\n","\u001b[K     |████████████████████████████████| 188 kB 69.2 MB/s \n","\u001b[?25hCollecting google-resumable-media<2.0dev,>=0.6.0\n","  Downloading google_resumable_media-1.3.3-py2.py3-none-any.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 4.5 MB/s \n","\u001b[?25hCollecting grpc-google-iam-v1<0.13dev,>=0.12.3\n","  Downloading grpc-google-iam-v1-0.12.3.tar.gz (13 kB)\n","Collecting google-cloud-storage<2.0.0dev,>=1.26.0\n","  Downloading google_cloud_storage-1.42.1-py2.py3-none-any.whl (105 kB)\n","\u001b[K     |████████████████████████████████| 105 kB 47.6 MB/s \n","\u001b[?25h  Downloading google_cloud_storage-1.42.0-py2.py3-none-any.whl (105 kB)\n","\u001b[K     |████████████████████████████████| 105 kB 30.9 MB/s \n","\u001b[?25h  Downloading google_cloud_storage-1.41.1-py2.py3-none-any.whl (105 kB)\n","\u001b[K     |████████████████████████████████| 105 kB 59.6 MB/s \n","\u001b[?25hCollecting google-crc32c<2.0dev,>=1.0\n","  Downloading google_crc32c-1.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.31->tfx) (0.6.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<3,>=2.7.3->tfx) (2.0.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner<1.0.2,>=1->tfx) (0.8.9)\n","Collecting terminaltables\n","  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner<1.0.2,>=1->tfx) (4.62.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner<1.0.2,>=1->tfx) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner<1.0.2,>=1->tfx) (0.22.2.post1)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/dist-packages (from kubernetes<13,>=10.0.1->tfx) (1.3.0)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.7/dist-packages (from kubernetes<13,>=10.0.1->tfx) (1.24.3)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.7/dist-packages (from kubernetes<13,>=10.0.1->tfx) (2021.5.30)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.31->tfx) (0.4.8)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<21,>=20->tfx) (2.4.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tfx) (2.10)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.31->tfx) (2.0.6)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (2.6.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (1.1.2)\n","Collecting grpcio<2,>=1.28.1\n","  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 19.4 MB/s \n","\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (0.37.0)\n","Collecting keras-nightly~=2.5.0.dev\n","  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 62.1 MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (0.2.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (1.1.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (1.12.1)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (3.3.0)\n","Collecting tensorflow-estimator<2.6.0,>=2.5.0\n","  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 71.4 MB/s \n","\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (1.6.3)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (3.1.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (1.12)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (0.4.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (1.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (4.8.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx) (3.1.1)\n","Requirement already satisfied: tensorflow-metadata<1.3,>=1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-data-validation<1.3.0,>=1.2.0->tfx) (1.2.0)\n","Collecting joblib<0.15,>=0.12\n","  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 75.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-data-validation<1.3.0,>=1.2.0->tfx) (1.1.5)\n","Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis<0.34,>=0.33->tfx) (7.6.5)\n","Collecting ipython<8,>=7\n","  Downloading ipython-7.28.0-py3-none-any.whl (788 kB)\n","\u001b[K     |████████████████████████████████| 788 kB 73.3 MB/s \n","\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (5.1.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.7.5)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (4.8.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.1.3)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.18.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (4.4.2)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.20-py3-none-any.whl (370 kB)\n","\u001b[K     |████████████████████████████████| 370 kB 60.6 MB/s \n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.2.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (4.10.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (1.0.2)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (3.5.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (5.1.3)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (5.1.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.8.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (4.7.1)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (2.6.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.2.5)\n","Collecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3,>=1.15\n","  Downloading tensorflow_serving_api-2.5.2-py2.py3-none-any.whl (38 kB)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.12.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (5.6.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (1.8.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (22.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2->tfx) (3.5.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (1.5.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (4.1.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.3)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7->tensorflow-model-analysis<0.34,>=0.33->tfx) (0.5.1)\n","Building wheels for collected packages: avro-python3, dill, future, google-apitools, grpc-google-iam-v1, keras-tuner, terminaltables\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=97b0c4e71a7c914a017142ee39333f625fe1f7887eb35aa82a0e77080379ea38\n","  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=675cf30d2fdf235831cfb528166e5f975f0afe0d60c1f5eff01b2d5e22eeb1e2\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=1f6b1da14e4068b024506e999230a3a10ecc3c41db6e20636da1a156b9549b15\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131040 sha256=74a0065e5ab85f2c7f4f5ae6d27dde633750b063650097f0020d8f886f436c37\n","  Stored in directory: /root/.cache/pip/wheels/19/b5/2f/1cc3cf2b31e7a9cd1508731212526d9550271274d351c96f16\n","  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for grpc-google-iam-v1: filename=grpc_google_iam_v1-0.12.3-py3-none-any.whl size=18515 sha256=81b5d5b4421eb681bcbbecebd0f779a9a016dbb313b3fa6f1a8ab77c619f4738\n","  Stored in directory: /root/.cache/pip/wheels/b9/ee/67/2e444183030cb8d31ce8b34cee34a7afdbd3ba5959ea846380\n","  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-py3-none-any.whl size=73198 sha256=66527b27f477b9c361cb0c5ca4828f91ffc8e82f900f92582fa7a6a99ee1af3d\n","  Stored in directory: /root/.cache/pip/wheels/0b/cf/2f/1a1749d3a3650fac3305a8d7f9237b6de7c41068e2f8520ca2\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=79d2a250f9d904ee510c73d7a849ce9cc8a63d3b52d04758709e65e6866a5bf5\n","  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n","Successfully built avro-python3 dill future google-apitools grpc-google-iam-v1 keras-tuner terminaltables\n","Installing collected packages: requests, prompt-toolkit, packaging, grpcio, ipython, grpcio-gcp, google-crc32c, tensorflow-estimator, pyarrow, proto-plus, orjson, keras-nightly, hdfs, grpc-google-iam-v1, google-resumable-media, google-cloud-core, future, fasteners, fastavro, dill, avro-python3, tensorflow, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-language, google-cloud-dlp, google-cloud-bigtable, google-cloud-bigquery, google-apitools, apache-beam, websocket-client, tensorflow-serving-api, joblib, attrs, tfx-bsl, terminaltables, ml-metadata, google-cloud-storage, docker, colorama, tensorflow-transform, tensorflow-model-analysis, tensorflow-data-validation, ml-pipelines-sdk, kubernetes, keras-tuner, google-cloud-aiplatform, tfx\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.0\n","    Uninstalling packaging-21.0:\n","      Successfully uninstalled packaging-21.0\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.40.0\n","    Uninstalling grpcio-1.40.0:\n","      Successfully uninstalled grpcio-1.40.0\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.6.0\n","    Uninstalling tensorflow-estimator-2.6.0:\n","      Successfully uninstalled tensorflow-estimator-2.6.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 3.0.0\n","    Uninstalling pyarrow-3.0.0:\n","      Successfully uninstalled pyarrow-3.0.0\n","  Attempting uninstall: google-resumable-media\n","    Found existing installation: google-resumable-media 0.4.1\n","    Uninstalling google-resumable-media-0.4.1:\n","      Successfully uninstalled google-resumable-media-0.4.1\n","  Attempting uninstall: google-cloud-core\n","    Found existing installation: google-cloud-core 1.0.3\n","    Uninstalling google-cloud-core-1.0.3:\n","      Successfully uninstalled google-cloud-core-1.0.3\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.6.0\n","    Uninstalling tensorflow-2.6.0:\n","      Successfully uninstalled tensorflow-2.6.0\n","  Attempting uninstall: google-cloud-language\n","    Found existing installation: google-cloud-language 1.2.0\n","    Uninstalling google-cloud-language-1.2.0:\n","      Successfully uninstalled google-cloud-language-1.2.0\n","  Attempting uninstall: google-cloud-bigquery\n","    Found existing installation: google-cloud-bigquery 1.21.0\n","    Uninstalling google-cloud-bigquery-1.21.0:\n","      Successfully uninstalled google-cloud-bigquery-1.21.0\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 1.0.1\n","    Uninstalling joblib-1.0.1:\n","      Successfully uninstalled joblib-1.0.1\n","  Attempting uninstall: attrs\n","    Found existing installation: attrs 21.2.0\n","    Uninstalling attrs-21.2.0:\n","      Successfully uninstalled attrs-21.2.0\n","  Attempting uninstall: google-cloud-storage\n","    Found existing installation: google-cloud-storage 1.18.1\n","    Uninstalling google-cloud-storage-1.18.1:\n","      Successfully uninstalled google-cloud-storage-1.18.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.18.0 which is incompatible.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.20 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.32.0 attrs-20.3.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 docker-4.4.4 fastavro-1.4.5 fasteners-0.16.3 future-0.18.2 google-apitools-0.5.31 google-cloud-aiplatform-0.7.1 google-cloud-bigquery-2.18.0 google-cloud-bigtable-1.7.0 google-cloud-core-1.7.2 google-cloud-dlp-1.0.0 google-cloud-language-1.3.0 google-cloud-pubsub-1.7.0 google-cloud-recommendations-ai-0.2.0 google-cloud-spanner-1.19.1 google-cloud-storage-1.41.1 google-cloud-videointelligence-1.16.1 google-cloud-vision-1.0.0 google-crc32c-1.2.0 google-resumable-media-1.3.3 grpc-google-iam-v1-0.12.3 grpcio-1.34.1 grpcio-gcp-0.2.2 hdfs-2.6.0 ipython-7.28.0 joblib-0.14.1 keras-nightly-2.5.0.dev2021032900 keras-tuner-1.0.1 kubernetes-12.0.1 ml-metadata-1.2.0 ml-pipelines-sdk-1.2.0 orjson-3.6.3 packaging-20.9 prompt-toolkit-3.0.20 proto-plus-1.19.0 pyarrow-2.0.0 requests-2.26.0 tensorflow-2.5.1 tensorflow-data-validation-1.2.0 tensorflow-estimator-2.5.0 tensorflow-model-analysis-0.33.0 tensorflow-serving-api-2.5.2 tensorflow-transform-1.2.0 terminaltables-3.1.0 tfx-1.2.0 tfx-bsl-1.2.0 websocket-client-1.2.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","google","prompt_toolkit"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"jstSZb9LK8lW"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_PzZ8KhKLRg","executionInfo":{"status":"ok","timestamp":1632812015345,"user_tz":-600,"elapsed":1066,"user":{"displayName":"Data Guru","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14667720544529076765"}},"outputId":"24e6e7d4-7bb4-4edd-9970-4bed31c2451b"},"source":["import tensorflow as tf \n","import tensorflow_transform as tft \n","import tensorflow_transform.beam as tft_beam \n","\n","from tensorflow_transform.tf_metadata import dataset_metadata\n","from tensorflow_transform.tf_metadata import schema_utils \n","\n","import pprint \n","import tempfile \n","\n","print(f'Tensorflow version: {tf.__version__}')\n","print(f'TFX Transform version: {tft.__version__}')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow version: 2.5.1\n","TFX Transform version: 1.2.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"83I9aSOdMHQM"},"source":["# Collect raw data \n","\n"]},{"cell_type":"code","metadata":{"id":"YzzlYaBtKLD_","executionInfo":{"status":"ok","timestamp":1632812276468,"user_tz":-600,"elapsed":304,"user":{"displayName":"Data Guru","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14667720544529076765"}}},"source":["raw_data = [\n","            {'x':1, 'y':1, 's':'hello'},\n","            {'x':2, 'y':2, 's':'world'},\n","            {'x':3, 'y':3, 's':'hello'}\n","]"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rOEtnX9KMq89"},"source":["# Define the metadata\n","\n","Next, you will define the metadata. This contains the schema that tells the types of each feature column (or key) in `raw_data`. You need to take note of a few things:\n","\n","* The transform function later expects the metadata to be packed in a [DatasetMetadata](https://github.com/tensorflow/transform/blob/master/tensorflow_transform/tf_metadata/dataset_metadata.py#L23) object. \n","* The constructor for the `DatasetMetadata` class expects a [Schema protocol buffer](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/schema.proto#L46) data type. You can use the [schema_from_feature_spec()](https://github.com/tensorflow/transform/blob/master/tensorflow_transform/tf_metadata/schema_utils.py#L36) method to generate that from a dictionary.\n","* To build the said dictionary, you will use the keys/column names of `raw_data` and assign a [FeatureSpecType](https://github.com/tensorflow/transform/blob/master/tensorflow_transform/common_types.py#L29) as values. This allows you to specify if the input is fixed or variable length (using [tf.io](https://www.tensorflow.org/api_docs/python/tf/io) classes), as well as to define the shape and data type."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zygLRMr_KK4n","executionInfo":{"status":"ok","timestamp":1632812629049,"user_tz":-600,"elapsed":308,"user":{"displayName":"Data Guru","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14667720544529076765"}},"outputId":"17ec9cf3-73a8-49a2-999c-5b17c5e1e494"},"source":["# define the schema as a DatasetMetadata object\n","raw_data_metadata = dataset_metadata.DatasetMetadata(\n","    \n","    # use convenience function to build a Schema protobuf\n","    schema_utils.schema_from_feature_spec({\n","        \n","        # define a dictionary mapping the keys to its feature spec type\n","        'y': tf.io.FixedLenFeature([], tf.float32),\n","        'x': tf.io.FixedLenFeature([], tf.float32),\n","        's': tf.io.FixedLenFeature([], tf.string)\n","    })\n",")\n","\n","print(raw_data_metadata._schema)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["feature {\n","  name: \"s\"\n","  type: BYTES\n","  presence {\n","    min_fraction: 1.0\n","  }\n","  shape {\n","  }\n","}\n","feature {\n","  name: \"x\"\n","  type: FLOAT\n","  presence {\n","    min_fraction: 1.0\n","  }\n","  shape {\n","  }\n","}\n","feature {\n","  name: \"y\"\n","  type: FLOAT\n","  presence {\n","    min_fraction: 1.0\n","  }\n","  shape {\n","  }\n","}\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"20j_GfAaOsrp"},"source":["# Create a preprocessing function\n","\n","The _preprocessing function_ is the most important concept of `tf.Transform`. A preprocessing function is where the transformation of the dataset really happens. It accepts and returns a dictionary of tensors, where a tensor means a <a target='_blank' href='https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/Tensor'><code>Tensor</code></a> or <a target='_blank' href='https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/SparseTensor'><code>SparseTensor</code></a>. There are two main groups of API calls that typically form the heart of a preprocessing function:\n","\n","1. **TensorFlow Ops:** Any function that accepts and returns tensors. These add TensorFlow operations to the graph that transforms raw data into transformed data one feature vector at a time.  These will run for every example, during both training and serving.\n","2. **TensorFlow Transform Analyzers:** Any of the analyzers provided by `tf.Transform`. Analyzers also accept and return tensors, but unlike TensorFlow ops they only run once during training, and typically make a full pass over the entire training dataset. They create <a target='_blank' href='https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/constant'>tensor constants</a>, which are added to your graph. For example, `tft.min` computes the minimum of a tensor over the training dataset.\n","\n","*Caution: When you apply your preprocessing function to serving inferences, the constants that were created by analyzers during training do not change.  If your data has trend or seasonality components, plan accordingly.*\n","\n","You can see available functions to transform your data [here](https://www.tensorflow.org/tfx/transform/api_docs/python/tft)."]},{"cell_type":"code","metadata":{"id":"fsEGvwyCOB4F","executionInfo":{"status":"ok","timestamp":1632813217594,"user_tz":-600,"elapsed":317,"user":{"displayName":"Data Guru","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14667720544529076765"}}},"source":["def processing_fn(inputs):\n","    \"\"\"Preprocess input columns into transformed columns.\"\"\"\n","    #extract the columns and assign to local variables\n","    x = inputs['x']\n","    y = inputs['y']\n","    s = inputs['s']\n","\n","    # data transformations using tft functions\n","    x_centered = x - tft.mean(x)\n","    y_normalized = tft.scale_to_0_1(y)\n","    s_integerized = tft.compute_and_apply_vocabulary(s)\n","    x_centered_times_y_normalized = (x_centered * y_normalized)\n","\n","    # return the transformed data\n","    return {\n","        'x_centered': x_centered,\n","        'y_normalized': y_normalized,\n","        's_integerized': s_integerized,\n","        'x_centered_times_y_normalized': x_centered_times_y_normalized\n","    }"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gYpYm6u1RAKU"},"source":["# Generate a constant graph with the required transformations"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"a8hJa3YsOB0u","executionInfo":{"status":"ok","timestamp":1632813937452,"user_tz":-600,"elapsed":5993,"user":{"displayName":"Data Guru","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14667720544529076765"}},"outputId":"6100e03b-e494-4a7c-b622-eebdac383751"},"source":["# ignore teh warnings\n","tf.get_logger().setLevel('ERROR')\n","\n","# a temporary directory is needed when analyzing the data\n","with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n","  # define the pipeline using Apache Beam syntax\n","  transformed_dataset, transform_fn = (\n","      \n","      # analyze and transform the dataset using the preprocessing function\n","      (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(processing_fn)\n","  )\n","\n","# unpack the transformed dataset\n","transformed_data, transformed_metadata = transformed_dataset\n","\n","# print the results\n","print('\\nRaw data:\\n{}\\n'.format(pprint.pformat(raw_data)))\n","print('Transformed data:\\n{}'.format(pprint.pformat(transformed_data)))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","        if (typeof window.interactive_beam_jquery == 'undefined') {\n","          var jqueryScript = document.createElement('script');\n","          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n","          jqueryScript.type = 'text/javascript';\n","          jqueryScript.onload = function() {\n","            var datatableScript = document.createElement('script');\n","            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n","            datatableScript.type = 'text/javascript';\n","            datatableScript.onload = function() {\n","              window.interactive_beam_jquery = jQuery.noConflict(true);\n","              window.interactive_beam_jquery(document).ready(function($){\n","                \n","              });\n","            }\n","            document.head.appendChild(datatableScript);\n","          };\n","          document.head.appendChild(jqueryScript);\n","        } else {\n","          window.interactive_beam_jquery(document).ready(function($){\n","            \n","          });\n","        }"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-932acf09-87ed-4293-bebd-7352dce9dbb3.json']\n","WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Raw data:\n","[{'s': 'hello', 'x': 1, 'y': 1},\n"," {'s': 'world', 'x': 2, 'y': 2},\n"," {'s': 'hello', 'x': 3, 'y': 3}]\n","\n","Transformed data:\n","[{'s_integerized': 0,\n","  'x_centered': -1.0,\n","  'x_centered_times_y_normalized': -0.0,\n","  'y_normalized': 0.0},\n"," {'s_integerized': 1,\n","  'x_centered': 0.0,\n","  'x_centered_times_y_normalized': 0.0,\n","  'y_normalized': 0.5},\n"," {'s_integerized': 0,\n","  'x_centered': 1.0,\n","  'x_centered_times_y_normalized': 1.0,\n","  'y_normalized': 1.0}]\n"]}]}]}